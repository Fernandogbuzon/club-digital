# ğŸ€ Scraper AutomÃ¡tico de Partidos ADESA 80

Sistema automatizado para obtener y actualizar los calendarios de partidos desde la FederaciÃ³n Andaluza de Baloncesto.

## ğŸ“‹ CaracterÃ­sticas

- âœ… **Scraping eficiente** con Cheerio (mÃ¡s rÃ¡pido que Puppeteer)
- âœ… **ActualizaciÃ³n inteligente** segÃºn el dÃ­a de la semana
- âœ… **DetecciÃ³n de cambios** para evitar commits innecesarios
- âœ… **Retry automÃ¡tico** en caso de fallo
- âœ… **TypeScript** con tipos estrictos
- âœ… **GitHub Actions** totalmente integrado

## ğŸ• Frecuencia de ActualizaciÃ³n

### Lunes a Viernes
**Cada 4 horas** (0:00, 4:00, 8:00, 12:00, 16:00, 20:00)
- Los horarios y fechas se actualizan entre semana

### SÃ¡bado y Domingo
**Cada 30 minutos**
- MÃ¡xima frescura durante los dÃ­as de partidos

### Manual
Puedes ejecutar el scraper manualmente desde:
- **GitHub**: Actions â†’ "ğŸ¤– Actualizar Partidos" â†’ Run workflow
- **Local**: `npm run scrape:partidos`

## ğŸš€ Uso Local

### InstalaciÃ³n
```bash
npm install
```

### Ejecutar scraper
```bash
# EjecuciÃ³n Ãºnica
npm run scrape:partidos

# Modo desarrollo (con watch)
npm run scrape:dev
```

### Build con scraping automÃ¡tico
```bash
npm run build
```
El comando build ejecuta automÃ¡ticamente el scraper antes de compilar.

## ğŸ“ Estructura de Datos

Los partidos se guardan en `src/data/partidos.json`:

```json
{
  "ultima_actualizacion": "2026-02-09T12:00:00.000Z",
  "total_partidos": 42,
  "partidos": [
    {
      "id": "2026-02-15_cadete_masculino_adesa_80_isaval_cba",
      "categoria": "Cadete Masculino",
      "competicion": "Comp. Copa AndalucÃ­a A",
      "equipoLocal": "ADESA 80",
      "equipoVisitante": "ISAVAL CBA",
      "fecha": "14/02/2026",
      "hora": "18:30",
      "pabellon": "PDVO. MUNICIPAL",
      "estado": "proximo",
      "fechaActualizacion": "2026-02-09T12:00:00.000Z"
    }
  ]
}
```

### Estados de Partidos

- `proximo`: Partido aÃºn no jugado
- `en_curso`: Partido en desarrollo (detectado por fecha/hora)
- `finalizado`: Partido completado (con resultado)

## ğŸ”§ ConfiguraciÃ³n

### URL de origen
En `src/scripts/scraper.ts`:
```typescript
const CONFIG = {
  url: 'https://www.andaluzabaloncesto.org/cadiz/resultados-club-196/adesa-80',
  timeout: 30000,
  retries: 1,
  outputPath: join(__dirname, '..', 'data', 'partidos.json'),
};
```

### Personalizar frecuencia
Edita `.github/workflows/scraper.yml`:
```yaml
schedule:
  - cron: '0 0,4,8,12,16,20 * * 1-5'  # Lunes-Viernes
  - cron: '*/30 * * * 0,6'             # SÃ¡bado-Domingo
```

## ğŸ“Š Logs y Monitoreo

### Ver logs de GitHub Actions
1. Ve a la pestaÃ±a **Actions**
2. Selecciona el workflow "ğŸ¤– Actualizar Partidos"
3. Revisa los logs de cada ejecuciÃ³n

### Logs locales
El scraper muestra logs detallados:
```
ğŸ€ Iniciando scraper de partidos ADESA 80...

ğŸ“¡ Obteniendo datos de: https://www.andaluzabaloncesto.org/...
âœ… HTML descargado (45.23 KB)

ğŸ” Parseando partidos...
âœ… 42 partidos encontrados

ğŸ’¾ Guardando partidos...
âœ… Datos guardados en: src/data/partidos.json

ğŸ“Š Resumen:
   - Total: 42 partidos
   - PrÃ³ximos: 38
   - En curso: 0
   - Finalizados: 4
   - Cambios detectados: SÃ­

â±ï¸  Completado en 2.45s
```

## ğŸ› ï¸ Troubleshooting

### El scraper no encuentra partidos
- Verifica que la URL sea correcta
- La estructura HTML de la web puede haber cambiado
- Revisa los selectores en la funciÃ³n `parsearPartidos()`

### GitHub Actions no se ejecuta
- Verifica que el workflow estÃ© habilitado
- Los cron jobs pueden tener hasta 15 minutos de retraso
- Ejecuta manualmente para verificar

### Errores de tipos TypeScript
```bash
npm install --save-dev @types/node tsx
```

## ğŸ“ˆ Consumo de GitHub Actions

**EstimaciÃ³n mensual:**
- Lunes-Viernes: 6 ejecuciones/dÃ­a Ã— 5 dÃ­as Ã— 4 semanas = 120 ejecuciones
- SÃ¡bado-Domingo: 48 ejecuciones/dÃ­a Ã— 2 dÃ­as Ã— 4 semanas = 384 ejecuciones
- **Total: ~500 ejecuciones/mes** (~1500 minutos)

âœ… Dentro del lÃ­mite gratuito de GitHub (2000 minutos/mes)

## ğŸ“ Notas

- Los commits automÃ¡ticos incluyen `[skip ci]` para evitar builds infinitos
- Solo se hace commit si hay cambios reales en los datos
- El scraper usa timeout de 30 segundos con 1 retry automÃ¡tico
- Compatible con cualquier hosting (Vercel, Netlify, etc.)

## ğŸ¤ Contribuir

Para modificar el scraper:
1. Edita `src/scripts/scraper.ts`
2. Prueba localmente: `npm run scrape:partidos`
3. Verifica el JSON generado en `src/data/partidos.json`
4. Commit y push los cambios

---

**Desarrollado para ADESA 80** ğŸ€
