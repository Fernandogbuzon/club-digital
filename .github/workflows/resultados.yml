name: âš¡ Resultados RÃ¡pidos ADESA 80

on:
  # Horario de partidos â€” cada 10 minutos
  schedule:
    # Viernes 17:00â€“23:50 UTC+1 â†’ 16:00â€“22:50 UTC
    - cron: '*/10 16-22 * * 5'
    # SÃ¡bado 9:00â€“22:50 UTC+1 â†’ 8:00â€“21:50 UTC
    - cron: '*/10 8-21 * * 6'
    # Domingo 9:00â€“22:50 UTC+1 â†’ 8:00â€“21:50 UTC
    - cron: '*/10 8-21 * * 0'
    # Entre semana 18:00â€“22:50 UTC+1 â†’ 17:00â€“21:50 UTC (por si hay partidos)
    - cron: '*/10 17-21 * * 1-4'

  # Lanzar manualmente desde GitHub
  workflow_dispatch:

concurrency:
  group: scraper-resultados
  cancel-in-progress: true

jobs:
  actualizar-resultados:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: ðŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: ðŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: ðŸ“¦ Instalar dependencias Python
        run: |
          pip install playwright playwright-stealth
          playwright install chromium
          playwright install-deps chromium

      - name: ðŸ” Comprobar partidos pendientes
        id: check
        run: |
          RESULT=$(python scraper_resultados.py --check 2>&1)
          echo "$RESULT"
          if echo "$RESULT" | grep -q "No hay partidos pendientes"; then
            echo "pendientes=false" >> $GITHUB_OUTPUT
            echo "âœ… No hay partidos pendientes"
          else
            echo "pendientes=true" >> $GITHUB_OUTPUT
            NPEND=$(echo "$RESULT" | grep -oP '\d+(?= partido\(s\) pendiente)')
            echo "num_pendientes=$NPEND" >> $GITHUB_OUTPUT
            echo "âš ï¸ $NPEND partido(s) pendiente(s)"
          fi

      - name: âš¡ Scraping rÃ¡pido de resultados
        if: steps.check.outputs.pendientes == 'true'
        run: |
          # xvfb para pantalla virtual (Cloudflare necesita modo headed)
          sudo apt-get install -y xvfb > /dev/null 2>&1
          xvfb-run --auto-servernum --server-args="-screen 0 1366x768x24" \
            python scraper_resultados.py 2>&1 || true

      - name: ðŸ“Š Verificar cambios en JSONs
        id: cambios
        run: |
          if git diff --quiet src/data/; then
            echo "hay_cambios=false" >> $GITHUB_OUTPUT
            echo "â„¹ï¸ No hay cambios en los datos"
          else
            echo "hay_cambios=true" >> $GITHUB_OUTPUT
            echo "âœ… Se detectaron resultados nuevos"
            git diff --stat src/data/
          fi

      - name: ðŸ’¾ Commit y push resultados
        if: steps.cambios.outputs.hay_cambios == 'true'
        run: |
          git config --local user.name "GitHub Actions Bot"
          git config --local user.email "actions@github.com"
          git add src/data/
          
          TIMESTAMP=$(TZ='Europe/Madrid' date '+%d/%m/%Y %H:%M')
          
          git commit -m "âš¡ Resultados actualizados - ${TIMESTAMP}" \
                     -m "ActualizaciÃ³n automÃ¡tica de resultados de partidos ADESA 80"
          
          git push

      - name: ðŸ“ Resumen
        if: always()
        run: |
          echo "### âš¡ Scraper RÃ¡pido de Resultados" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Fecha:** $(TZ='Europe/Madrid' date '+%d/%m/%Y %H:%M') (EspaÃ±a)" >> $GITHUB_STEP_SUMMARY
          echo "**Pendientes:** ${{ steps.check.outputs.pendientes }}" >> $GITHUB_STEP_SUMMARY
          echo "**Resultados nuevos:** ${{ steps.cambios.outputs.hay_cambios || 'N/A' }}" >> $GITHUB_STEP_SUMMARY
